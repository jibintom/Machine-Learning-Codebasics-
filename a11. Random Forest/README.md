

## Random Forest

![enter image description here](https://raw.githubusercontent.com/jibintom/Machine-Learning-Codebasics-/main/a11.%20Random%20Forest/Images/desion%20tree.png)


The random forest algorithm is another popular machine learning technique used in regression and classification and its upgrade version of the decision tree classifier method, in the decision tree classifier method we are building a single decision tree from a given data set


![enter image description here](https://raw.githubusercontent.com/jibintom/Machine-Learning-Codebasics-/main/a11.%20Random%20Forest/Images/random%20forest.png)


Now, in order to build multiple decision trees out of a single data set, one of the approaches is to take the data set and divide it into a batch of random data sets. Then build a decision tree for each of them. So we have a random sampling here, it's called a random forest, and now we have multiple trees and our forest is being formed already. Once it is trained, we give the things that want to predict, and they will all come up with a different decision. Finally, we may take a majority of what out of it and get a decision.  This is the basic idea behind the **random forest algorithm**.
